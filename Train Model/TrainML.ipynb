{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twvMFv-f-STk",
        "outputId": "9a0c7305-9d42-402a-b8cc-2840c21f3c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes, DecisionTreeClassifier, GBTClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "TKtCHTXe-UFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Text Classification with DL and ML Models\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "cKWd1LD8-Xr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data = spark.read.csv('/content/drive/MyDrive/data/train/train_final.csv', header=True, inferSchema=True)\n",
        "test_data = spark.read.csv('/content/drive/MyDrive/data/test/test_final.csv', header=True, inferSchema=True)\n",
        "\n",
        "train_data = train_data.dropna(subset=[\"text\", \"label\"]).withColumn(\"label\", train_data[\"label\"].cast(\"int\"))\n",
        "test_data = test_data.dropna(subset=[\"text\", \"label\"]).withColumn(\"label\", test_data[\"label\"].cast(\"int\"))\n",
        "\n",
        "train_data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAZXhCh_-c60",
        "outputId": "63fcb36a-e42b-4ec1-f846-e6c941d04aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "+--------------------+-----+\n",
            "|                text|label|\n",
            "+--------------------+-----+\n",
            "|em được làm fan c...|    0|\n",
            "|đúng là bọn mắt h...|    2|\n",
            "|đậu văn cường giờ...|    0|\n",
            "|côn đồ cục súc vô...|    2|\n",
            "|từ lý thuyết đến ...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = train_data.dropna(subset=[\"label\"])\n",
        "test_data = test_data.dropna(subset=[\"label\"])\n"
      ],
      "metadata": {
        "id": "X6CiIlg9_NOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length, trim, col\n",
        "\n",
        "train_data = train_data.filter((length(trim(col(\"text\"))) > 0))\n",
        "test_data = test_data.filter((length(trim(col(\"text\"))) > 0))"
      ],
      "metadata": {
        "id": "MduvAw-t_ZDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, when, isnull\n",
        "train_data.select([count(when(isnull(c), c)).alias(c) for c in train_data.columns]).show()\n",
        "test_data.select([count(when(isnull(c), c)).alias(c) for c in train_data.columns]).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyZD9Pj_-rXO",
        "outputId": "923a007c-33d7-44b4-dd4a-f122150ce10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|text|label|\n",
            "+----+-----+\n",
            "|   0|    0|\n",
            "+----+-----+\n",
            "\n",
            "+----+-----+\n",
            "|text|label|\n",
            "+----+-----+\n",
            "|   0|    0|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Train data schema:\")\n",
        "train_data.printSchema()\n",
        "\n",
        "print(\"\\nTest data schema:\")\n",
        "test_data.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrTZYumF_l6s",
        "outputId": "017afdb8-1f49-4990-8d4a-106d6dc059bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data schema:\n",
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n",
            "\n",
            "Test data schema:\n",
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Train data types:\", train_data.dtypes)\n",
        "print(\"Test data types:\", test_data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuFj30Y5_o0k",
        "outputId": "7b996b20-9a13-4858-da49-5a6bc58e10f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data types: [('text', 'string'), ('label', 'int')]\n",
            "Test data types: [('text', 'string'), ('label', 'int')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=5000)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n"
      ],
      "metadata": {
        "id": "FyFPEHug_wiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra các giá trị nhãn trong dữ liệu huấn luyện\n",
        "train_data.select(\"label\").distinct().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_97EuUbAdai",
        "outputId": "79ee230e-b374-486b-80cb-cca0f3c0bb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|label|\n",
            "+-----+\n",
            "|    1|\n",
            "|    2|\n",
            "|    0|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = {\n",
        "    'Logistic Regression': Pipeline(stages=[tokenizer, remover, hashing_tf, idf, LogisticRegression(featuresCol=\"features\", labelCol=\"label\")]),\n",
        "    'Random Forest': Pipeline(stages=[tokenizer, remover, hashing_tf, idf, RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)]),\n",
        "    'Naive Bayes': Pipeline(stages=[tokenizer, remover, hashing_tf, idf, NaiveBayes(featuresCol=\"features\", labelCol=\"label\")]),\n",
        "    'Decision Tree': Pipeline(stages=[tokenizer, remover, hashing_tf, idf, DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")]),\n",
        "}\n",
        "\n",
        "pipeline_path = '/content/drive/MyDrive/models/'"
      ],
      "metadata": {
        "id": "EKFSFIAMFKyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, pipeline_model in pipelines.items():\n",
        "    print(f\"Training and saving pipeline for {model_name}...\")\n",
        "    model = pipeline_model.fit(train_data)  # Huấn luyện pipeline\n",
        "    model.save(pipeline_path + f'{model_name}_pipeline')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGJgDFy9FULM",
        "outputId": "a07af04c-25f6-4d26-bd15-a68d6b716322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and saving pipeline for Logistic Regression...\n",
            "Training and saving pipeline for Random Forest...\n",
            "Training and saving pipeline for Naive Bayes...\n",
            "Training and saving pipeline for Decision Tree...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "logistic_regression_pipeline = PipelineModel.load(pipeline_path + 'Logistic Regression_pipeline')\n",
        "random_forest_pipeline = PipelineModel.load(pipeline_path + 'Random Forest_pipeline')\n",
        "naive_bayes_pipeline = PipelineModel.load(pipeline_path + 'Naive Bayes_pipeline')\n",
        "decision_tree_pipeline = PipelineModel.load(pipeline_path + 'Decision Tree_pipeline')"
      ],
      "metadata": {
        "id": "3oE5SUXeF8lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n"
      ],
      "metadata": {
        "id": "iQJWsKfPGK34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_predictions = logistic_regression_pipeline.transform(test_data)\n",
        "random_forest_predictions = random_forest_pipeline.transform(test_data)\n",
        "naive_bayes_predictions = naive_bayes_pipeline.transform(test_data)\n",
        "decision_tree_predictions = decision_tree_pipeline.transform(test_data)"
      ],
      "metadata": {
        "id": "zZmtEsCTGNVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy = evaluator.evaluate(logistic_regression_predictions)\n",
        "random_forest_accuracy = evaluator.evaluate(random_forest_predictions)\n",
        "naive_bayes_accuracy = evaluator.evaluate(naive_bayes_predictions)\n",
        "decision_tree_accuracy = evaluator.evaluate(decision_tree_predictions)"
      ],
      "metadata": {
        "id": "TR3eb-iwGQrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Logistic Regression Accuracy: {logistic_regression_accuracy:.4f}\")\n",
        "print(f\"Random Forest Accuracy: {random_forest_accuracy:.4f}\")\n",
        "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy:.4f}\")\n",
        "print(f\"Decision Tree Accuracy: {decision_tree_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQBl7cPPGT9h",
        "outputId": "0a2857a0-01a2-4dde-c967-5e998f34c8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.7795\n",
            "Random Forest Accuracy: 0.8306\n",
            "Naive Bayes Accuracy: 0.7163\n",
            "Decision Tree Accuracy: 0.8380\n"
          ]
        }
      ]
    }
  ]
}